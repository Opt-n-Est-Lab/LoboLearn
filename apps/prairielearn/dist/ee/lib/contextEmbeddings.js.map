{"version":3,"file":"contextEmbeddings.js","sourceRoot":"","sources":["../../../src/ee/lib/contextEmbeddings.ts"],"names":[],"mappings":"AAAA,OAAO,KAAK,IAAI,MAAM,MAAM,CAAC;AAE7B,OAAO,EAAE,MAAM,UAAU,CAAC;AAC1B,OAAO,IAAI,MAAM,MAAM,CAAC;AACxB,OAAO,EAAe,MAAM,QAAQ,CAAC;AAErC,OAAO,EAAE,YAAY,EAAE,gBAAgB,EAAE,SAAS,EAAE,MAAM,wBAAwB,CAAC;AAEnF,OAAO,EAAE,wCAAwC,EAAE,MAAM,uBAAuB,CAAC;AACjF,OAAO,EAAE,oBAAoB,EAAE,MAAM,oBAAoB,CAAC;AAC1D,OAAO,EAAkB,eAAe,EAAE,MAAM,0BAA0B,CAAC;AAE3E,OAAO,EAAsB,0BAA0B,EAAE,MAAM,oCAAoC,CAAC;AACpG,OAAO,EAAE,uBAAuB,EAAE,MAAM,yCAAyC,CAAC;AAElF,MAAM,GAAG,GAAG,YAAY,CAAC,MAAM,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC;AAE1C;;;;;GAKG;AACH,MAAM,UAAU,cAAc,CAAC,GAAa;IAC1C,OAAO,IAAI,GAAG,CAAC,IAAI,CAAC,IAAI,CAAC,GAAG,CAAC;AAC/B,CAAC;AAED;;;;;GAKG;AACH,MAAM,UAAU,mBAAmB,CAAC,WAAmB;IACrD,OAAO,QAAQ,WAAW,EAAE,CAAC;AAC/B,CAAC;AAED;;;;;;;GAOG;AACH,MAAM,CAAC,KAAK,UAAU,eAAe,CAAC,MAAc,EAAE,IAAY,EAAE,UAAkB;IACpF,MAAM,SAAS,GAAG,MAAM,MAAM,CAAC,UAAU,CAAC,MAAM,CAAC;QAC/C,KAAK,EAAE,IAAI;QACX,KAAK,EAAE,wBAAwB;QAC/B,eAAe,EAAE,OAAO;QACxB,IAAI,EAAE,UAAU;KACjB,CAAC,CAAC;IAEH,OAAO,SAAS,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC,SAAS,CAAC;AACrC,CAAC;AAED;;;;;;;;GAQG;AACH,KAAK,UAAU,mBAAmB,CAChC,MAAc,EACd,QAAgB,EAChB,GAAkB,EAClB,GAAc,EACd,UAAkB;IAElB,MAAM,KAAK,GAAG,MAAM,gBAAgB,CAClC,GAAG,CAAC,sBAAsB,EAC1B,EAAE,QAAQ,EAAE,QAAQ,EAAE,QAAQ,EAAE,GAAG,CAAC,OAAO,EAAE,EAC7C,wCAAwC,CACzC,CAAC;IAEF,IAAI,KAAK,IAAI,KAAK,CAAC,QAAQ,KAAK,GAAG,CAAC,IAAI,EAAE,CAAC;QACzC,GAAG,CAAC,IAAI,CAAC,aAAa,QAAQ,KAAK,GAAG,CAAC,OAAO,8CAA8C,CAAC,CAAC;QAC9F,OAAO;IACT,CAAC;IAED,GAAG,CAAC,IAAI,CAAC,uBAAuB,QAAQ,KAAK,GAAG,CAAC,OAAO,sBAAsB,CAAC,CAAC;IAChF,MAAM,SAAS,GAAG,MAAM,eAAe,CAAC,MAAM,EAAE,GAAG,CAAC,IAAI,EAAE,UAAU,CAAC,CAAC;IACtE,MAAM,SAAS,CACb,GAAG,CAAC,gBAAgB,EACpB;QACE,QAAQ,EAAE,QAAQ;QAClB,QAAQ,EAAE,GAAG,CAAC,IAAI;QAClB,SAAS,EAAE,cAAc,CAAC,SAAS,CAAC;QACpC,QAAQ,EAAE,GAAG,CAAC,OAAO;KACtB,EACD,wCAAwC,CACzC,CAAC;AACJ,CAAC;AAED;;;;;;GAMG;AACH,MAAM,CAAC,KAAK,UAAU,oBAAoB,CAAC,MAAc,EAAE,WAAmB;IAC5E,MAAM,SAAS,GAAG,MAAM,eAAe,CAAC;QACtC,IAAI,EAAE,kCAAkC;QACxC,WAAW,EAAE,2CAA2C;KACzD,CAAC,CAAC;IAEH,SAAS,CAAC,mBAAmB,CAAC,KAAK,EAAE,GAAG,EAAE,EAAE;QAC1C,MAAM,qBAAqB,GAAG,IAAI,CAAC,IAAI,CACrC,oBAAoB,EACpB,kCAAkC,CACnC,CAAC;QACF,MAAM,gBAAgB,GAAa,EAAE,CAAC;QACtC,IAAI,KAAK,EAAE,MAAM,IAAI,IAAI,IAAI,CAAC,qBAAqB,CAAC,EAAE,CAAC;YACrD,IAAI,IAAI,CAAC,KAAK,CAAC,WAAW,EAAE;gBAAE,SAAS;YAEvC,MAAM,QAAQ,GAAG,IAAI,CAAC,QAAQ,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;YAC1C,IAAI,QAAQ,KAAK,eAAe;gBAAE,SAAS;YAE3C,MAAM,QAAQ,GAAG,MAAM,uBAAuB,CAAC,IAAI,CAAC,OAAO,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC,CAAC;YACxE,IAAI,QAAQ,EAAE,CAAC;gBACb,MAAM,mBAAmB,CACvB,MAAM,EACN,IAAI,CAAC,QAAQ,CAAC,oBAAoB,EAAE,IAAI,CAAC,IAAI,CAAC,EAC9C,EAAE,IAAI,EAAE,QAAQ,EAAE,OAAO,EAAE,EAAE,EAAE,EAC/B,GAAG,EACH,mBAAmB,CAAC,WAAW,CAAC,CACjC,CAAC;gBACF,gBAAgB,CAAC,IAAI,CAAC,IAAI,CAAC,QAAQ,CAAC,oBAAoB,EAAE,IAAI,CAAC,IAAI,CAAC,CAAC,CAAC;YACxE,CAAC;QACH,CAAC;QAED,MAAM,eAAe,GAAG,IAAI,CAAC,IAAI,CAAC,oBAAoB,EAAE,kBAAkB,CAAC,CAAC;QAC5E,gBAAgB,CAAC,IAAI,CAAC,IAAI,CAAC,QAAQ,CAAC,oBAAoB,EAAE,eAAe,CAAC,CAAC,CAAC;QAC5E,MAAM,QAAQ,GAAG,MAAM,EAAE,CAAC,QAAQ,CAAC,eAAe,EAAE,EAAE,QAAQ,EAAE,OAAO,EAAE,CAAC,CAAC;QAC3E,MAAM,KAAK,GAAG,MAAM,0BAA0B,CAAC,QAAQ,CAAC,CAAC;QACzD,KAAK,MAAM,GAAG,IAAI,KAAK,EAAE,CAAC;YACxB,MAAM,mBAAmB,CACvB,MAAM,EACN,IAAI,CAAC,QAAQ,CAAC,oBAAoB,EAAE,eAAe,CAAC,EACpD,GAAG,EACH,GAAG,EACH,mBAAmB,CAAC,WAAW,CAAC,CACjC,CAAC;QACJ,CAAC;QAED,MAAM,SAAS,CACb,GAAG,CAAC,wBAAwB,EAC5B;YACE,SAAS,EAAE,gBAAgB;YAC3B,SAAS,EAAE,KAAK,CAAC,GAAG,CAAC,CAAC,GAAG,EAAE,EAAE,CAAC,GAAG,CAAC,OAAO,CAAC,CAAC,MAAM,CAAC,CAAC,EAAE,CAAC,CAAC;SACxD,EACD,wCAAwC,CACzC,CAAC;IACJ,CAAC,CAAC,CAAC;IACH,OAAO,SAAS,CAAC,aAAa,CAAC;AACjC,CAAC","sourcesContent":["import * as path from 'path';\n\nimport fs from 'fs-extra';\nimport klaw from 'klaw';\nimport { type OpenAI } from 'openai';\n\nimport { loadSqlEquiv, queryOptionalRow, queryRows } from '@prairielearn/postgres';\n\nimport { QuestionGenerationContextEmbeddingSchema } from '../../lib/db-types.js';\nimport { REPOSITORY_ROOT_PATH } from '../../lib/paths.js';\nimport { type ServerJob, createServerJob } from '../../lib/server-jobs.js';\n\nimport { type DocumentChunk, buildContextForElementDocs } from './context-parsers/documentation.js';\nimport { buildContextForQuestion } from './context-parsers/template-questions.js';\n\nconst sql = loadSqlEquiv(import.meta.url);\n\n/**\n * Converts an embedding array to a pgvector-compatible string.\n *\n * @param vec The embedding vector to convert.\n * @returns A pgvector-compatible representation of the embedding vector.\n */\nexport function vectorToString(vec: number[]) {\n  return `[${vec.join(', ')}]`;\n}\n\n/**\n * Converts a PrairieLearn authenticated user ID to a OpenAI user ID.\n *\n * @param authnUserId The PrairieLearn authenticated user ID.\n * @returns An OpenAI user ID (for internal tracking).\n */\nexport function openAiUserFromAuthn(authnUserId: string): string {\n  return `user_${authnUserId}`;\n}\n\n/**\n * Converts text to a semantic embedding.\n *\n * @param client The OpenAI client to use.\n * @param text The document text to embed.\n * @param openAiUser The OpenAI userstring requesting the embeddng.\n * @returns The resultant document embedding.\n */\nexport async function createEmbedding(client: OpenAI, text: string, openAiUser: string) {\n  const embedding = await client.embeddings.create({\n    input: text,\n    model: 'text-embedding-3-small',\n    encoding_format: 'float',\n    user: openAiUser,\n  });\n\n  return embedding.data[0].embedding;\n}\n\n/**\n * Inserts a document chunk into the vectorstore.\n *\n * @param client The OpenAI client to use.\n * @param filepath The filepath of the document to add.\n * @param doc The document chunk to add.\n * @param job The server job calling this function.\n * @param openAiUser The OpenAI userstring requesting the adding of the document chunk.\n */\nasync function insertDocumentChunk(\n  client: OpenAI,\n  filepath: string,\n  doc: DocumentChunk,\n  job: ServerJob,\n  openAiUser: string,\n) {\n  const chunk = await queryOptionalRow(\n    sql.check_doc_chunk_exists,\n    { doc_path: filepath, chunk_id: doc.chunkId },\n    QuestionGenerationContextEmbeddingSchema,\n  );\n\n  if (chunk && chunk.doc_text === doc.text) {\n    job.info(`Chunk for ${filepath} (${doc.chunkId}}) already exists in the database. Skipping.`);\n    return;\n  }\n\n  job.info(`Inserting chunk for ${filepath} (${doc.chunkId}) into the database.`);\n  const embedding = await createEmbedding(client, doc.text, openAiUser);\n  await queryRows(\n    sql.insert_embedding,\n    {\n      doc_path: filepath,\n      doc_text: doc.text,\n      embedding: vectorToString(embedding),\n      chunk_id: doc.chunkId,\n    },\n    QuestionGenerationContextEmbeddingSchema,\n  );\n}\n\n/**\n * Creates a job to synchronize predefined context (consisting of example course questions + element docs) with the vectorstore.\n *\n * @param client The OpenAI client to use.\n * @param authnUserId The OpenAI userstring of the user requesting the sync.\n * @returns The job ID of the synchronization job.\n */\nexport async function syncContextDocuments(client: OpenAI, authnUserId: string) {\n  const serverJob = await createServerJob({\n    type: 'sync_question_generation_context',\n    description: 'Generate embeddings for context documents',\n  });\n\n  serverJob.executeInBackground(async (job) => {\n    const templateQuestionsPath = path.join(\n      REPOSITORY_ROOT_PATH,\n      'exampleCourse/questions/template',\n    );\n    const allowedFilepaths: string[] = [];\n    for await (const file of klaw(templateQuestionsPath)) {\n      if (file.stats.isDirectory()) continue;\n\n      const filename = path.basename(file.path);\n      if (filename !== 'question.html') continue;\n\n      const fileText = await buildContextForQuestion(path.dirname(file.path));\n      if (fileText) {\n        await insertDocumentChunk(\n          client,\n          path.relative(REPOSITORY_ROOT_PATH, file.path),\n          { text: fileText, chunkId: '' },\n          job,\n          openAiUserFromAuthn(authnUserId),\n        );\n        allowedFilepaths.push(path.relative(REPOSITORY_ROOT_PATH, file.path));\n      }\n    }\n\n    const elementDocsPath = path.join(REPOSITORY_ROOT_PATH, 'docs/elements.md');\n    allowedFilepaths.push(path.relative(REPOSITORY_ROOT_PATH, elementDocsPath));\n    const fileText = await fs.readFile(elementDocsPath, { encoding: 'utf-8' });\n    const files = await buildContextForElementDocs(fileText);\n    for (const doc of files) {\n      await insertDocumentChunk(\n        client,\n        path.relative(REPOSITORY_ROOT_PATH, elementDocsPath),\n        doc,\n        job,\n        openAiUserFromAuthn(authnUserId),\n      );\n    }\n\n    await queryRows(\n      sql.delete_unused_doc_chunks,\n      {\n        doc_paths: allowedFilepaths,\n        chunk_ids: files.map((doc) => doc.chunkId).concat(['']),\n      },\n      QuestionGenerationContextEmbeddingSchema,\n    );\n  });\n  return serverJob.jobSequenceId;\n}\n"]}